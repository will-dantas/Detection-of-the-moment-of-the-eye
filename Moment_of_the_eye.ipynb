{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "unauthorized-england",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import pandas as pd\n",
    "import dlib\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funny-ancient",
   "metadata": {},
   "source": [
    "# 1. Montando dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "activated-archive",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataframe():\n",
    "    '''\n",
    "    Carrega um dataframe Pandas com as imagens para o treinamento do modelo\n",
    "    \n",
    "    '''\n",
    "    dados = {\n",
    "        \"File\": [],\n",
    "        \"Label\": [],\n",
    "        \"Target\": [],\n",
    "        \"Image\": [],\n",
    "    }\n",
    "\n",
    "    open_eyes = os.listdir(f\"facialImagens{os.sep}openeye\") \n",
    "    closed_eyes = os.listdir(f\"facialImagens{os.sep}closedeye\")\n",
    "\n",
    "    for arquivo in open_eyes:\n",
    "        dados[\"File\"].append(f\"facialImagens{os.sep}openeye{os.sep}{arquivo}\")\n",
    "        dados[\"Label\"].append(f\"Open eye\")\n",
    "        dados[\"Target\"].append(1)\n",
    "        img = cv.cvtColor(cv.imread(f\"facialImagens{os.sep}openeye{os.sep}{arquivo}\"), cv.COLOR_BGR2GRAY).flatten()\n",
    "        dados[\"Image\"].append(img)\n",
    "        \n",
    "    for arquivo in closed_eyes:\n",
    "        dados[\"File\"].append(f\"facialImagens{os.sep}closedeye{os.sep}{arquivo}\")\n",
    "        dados[\"Label\"].append(f\"Closed eye\")\n",
    "        dados[\"Target\"].append(0)\n",
    "        img = cv.cvtColor(cv.imread(f\"facialImagens{os.sep}closedeye{os.sep}{arquivo}\"), cv.COLOR_BGR2GRAY).flatten()\n",
    "        dados[\"Image\"].append(img)\n",
    "        \n",
    "    dataframe = pd.DataFrame(dados)\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "assisted-insight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Label</th>\n",
       "      <th>Target</th>\n",
       "      <th>Image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>facialImagens\\openeye\\Aaron_Guiel_0001.jpg</td>\n",
       "      <td>Open eye</td>\n",
       "      <td>1</td>\n",
       "      <td>[7, 10, 14, 17, 19, 24, 30, 36, 42, 43, 46, 49...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>facialImagens\\openeye\\Abdel_Madi_Shabneh_0001.jpg</td>\n",
       "      <td>Open eye</td>\n",
       "      <td>1</td>\n",
       "      <td>[168, 161, 154, 140, 111, 89, 103, 133, 115, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>facialImagens\\openeye\\Abid_Hamid_Mahmud_Al-Tik...</td>\n",
       "      <td>Open eye</td>\n",
       "      <td>1</td>\n",
       "      <td>[202, 203, 199, 192, 190, 195, 200, 202, 205, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>facialImagens\\openeye\\Adam_Rich_0001.jpg</td>\n",
       "      <td>Open eye</td>\n",
       "      <td>1</td>\n",
       "      <td>[79, 41, 10, 8, 13, 10, 10, 17, 6, 24, 32, 32,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>facialImagens\\openeye\\Adolfo_Aguilar_Zinser_00...</td>\n",
       "      <td>Open eye</td>\n",
       "      <td>1</td>\n",
       "      <td>[93, 118, 125, 107, 99, 110, 114, 105, 107, 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2418</th>\n",
       "      <td>facialImagens\\closedeye\\closed_eye_2804.jpg_fa...</td>\n",
       "      <td>Closed eye</td>\n",
       "      <td>0</td>\n",
       "      <td>[39, 39, 39, 39, 39, 39, 39, 39, 39, 38, 38, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2419</th>\n",
       "      <td>facialImagens\\closedeye\\closed_eye_2808.BMP_fa...</td>\n",
       "      <td>Closed eye</td>\n",
       "      <td>0</td>\n",
       "      <td>[113, 114, 116, 119, 122, 124, 125, 126, 125, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2420</th>\n",
       "      <td>facialImagens\\closedeye\\closed_eye_2813.BMP_fa...</td>\n",
       "      <td>Closed eye</td>\n",
       "      <td>0</td>\n",
       "      <td>[38, 14, 21, 57, 79, 85, 89, 90, 57, 60, 68, 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2421</th>\n",
       "      <td>facialImagens\\closedeye\\closed_eye_2817.jpg_fa...</td>\n",
       "      <td>Closed eye</td>\n",
       "      <td>0</td>\n",
       "      <td>[74, 66, 55, 45, 41, 40, 37, 32, 18, 22, 24, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2422</th>\n",
       "      <td>facialImagens\\closedeye\\closed_eye_2847.jpg_fa...</td>\n",
       "      <td>Closed eye</td>\n",
       "      <td>0</td>\n",
       "      <td>[13, 5, 1, 4, 6, 2, 1, 3, 5, 7, 12, 18, 23, 28...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2423 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   File       Label  Target  \\\n",
       "0            facialImagens\\openeye\\Aaron_Guiel_0001.jpg    Open eye       1   \n",
       "1     facialImagens\\openeye\\Abdel_Madi_Shabneh_0001.jpg    Open eye       1   \n",
       "2     facialImagens\\openeye\\Abid_Hamid_Mahmud_Al-Tik...    Open eye       1   \n",
       "3              facialImagens\\openeye\\Adam_Rich_0001.jpg    Open eye       1   \n",
       "4     facialImagens\\openeye\\Adolfo_Aguilar_Zinser_00...    Open eye       1   \n",
       "...                                                 ...         ...     ...   \n",
       "2418  facialImagens\\closedeye\\closed_eye_2804.jpg_fa...  Closed eye       0   \n",
       "2419  facialImagens\\closedeye\\closed_eye_2808.BMP_fa...  Closed eye       0   \n",
       "2420  facialImagens\\closedeye\\closed_eye_2813.BMP_fa...  Closed eye       0   \n",
       "2421  facialImagens\\closedeye\\closed_eye_2817.jpg_fa...  Closed eye       0   \n",
       "2422  facialImagens\\closedeye\\closed_eye_2847.jpg_fa...  Closed eye       0   \n",
       "\n",
       "                                                  Image  \n",
       "0     [7, 10, 14, 17, 19, 24, 30, 36, 42, 43, 46, 49...  \n",
       "1     [168, 161, 154, 140, 111, 89, 103, 133, 115, 1...  \n",
       "2     [202, 203, 199, 192, 190, 195, 200, 202, 205, ...  \n",
       "3     [79, 41, 10, 8, 13, 10, 10, 17, 6, 24, 32, 32,...  \n",
       "4     [93, 118, 125, 107, 99, 110, 114, 105, 107, 10...  \n",
       "...                                                 ...  \n",
       "2418  [39, 39, 39, 39, 39, 39, 39, 39, 39, 38, 38, 3...  \n",
       "2419  [113, 114, 116, 119, 122, 124, 125, 126, 125, ...  \n",
       "2420  [38, 14, 21, 57, 79, 85, 89, 90, 57, 60, 68, 8...  \n",
       "2421  [74, 66, 55, 45, 41, 40, 37, 32, 18, 22, 24, 2...  \n",
       "2422  [13, 5, 1, 4, 6, 2, 1, 3, 5, 7, 12, 18, 23, 28...  \n",
       "\n",
       "[2423 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = load_dataframe() #Carregando dataframe com as imagens para treinamento\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artistic-barrier",
   "metadata": {},
   "source": [
    "# 2. Divide o dataframe em conjunto de treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "theoretical-machine",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(dataframe[\"Image\"])\n",
    "y = list(dataframe[\"Target\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.33, random_state=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-naples",
   "metadata": {},
   "source": [
    "# 3. Carrega o detector de face pelo Dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hawaiian-estate",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector() \n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dated-addition",
   "metadata": {},
   "source": [
    "# 4. Função que demarca a região dos olhos por landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "talented-channel",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eye_region(eye_points, landmarks):\n",
    "    eye_region = np.array([(landmarks.part(eye_points[0]).x, landmarks.part(eye_points[0]).y),\n",
    "                            (landmarks.part(eye_points[1]).x, landmarks.part(eye_points[1]).y),\n",
    "                            (landmarks.part(eye_points[2]).x, landmarks.part(eye_points[2]).y),\n",
    "                            (landmarks.part(eye_points[3]).x, landmarks.part(eye_points[3]).y),\n",
    "                            (landmarks.part(eye_points[4]).x, landmarks.part(eye_points[4]).y),\n",
    "                            (landmarks.part(eye_points[5]).x, landmarks.part(eye_points[5]).y)], np.int32)\n",
    "    return eye_region"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relevant-admission",
   "metadata": {},
   "source": [
    "# 5. Detecta a face e extrai os landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "duplicate-sweden",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eye(img, faces):\n",
    "    for face in faces:\n",
    "        # Procurando os marcos\n",
    "        landmarks = predictor(image=img, box=face)\n",
    "    \n",
    "        left_eye_region = eye_region([36, 37, 38, 39, 40, 41], landmarks)\n",
    "        right_eye_region = eye_region([42, 43, 44, 45, 46, 47], landmarks)\n",
    "        eye = cv.polylines(img, [left_eye_region,right_eye_region], True, 255, 2)\n",
    "        \n",
    "    return eye"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charming-chemical",
   "metadata": {},
   "source": [
    "# 6. extração das features das imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fitting-episode",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(n_components=90)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PCA para extração de features das imagen\n",
    "\n",
    "pca = PCA(n_components=90)\n",
    "pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-craps",
   "metadata": {},
   "source": [
    "# 7. Classificação da imagens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "reliable-capacity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.56      0.64       799\n",
      "           1       0.65      0.82      0.73       825\n",
      "\n",
      "    accuracy                           0.69      1624\n",
      "   macro avg       0.70      0.69      0.68      1624\n",
      "weighted avg       0.70      0.69      0.68      1624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Modelo K-Nearest Neighbors\n",
    "\n",
    "grid_params = {\"n_neighbors\": [2, 3, 5, 11, 19, 23, 29],\n",
    "               \"weights\": [\"uniform\", \"distance\"],\n",
    "               \"metric\": [\"euclidean\", \"manhattam\", \"cosine\", \"l1\", \"l2\"]\n",
    "              }\n",
    "\n",
    "knn_model = GridSearchCV(KNeighborsClassifier(), grid_params, refit=True)\n",
    "\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# predizendo o teste\n",
    "y_pred = knn_model.predict(X_test)\n",
    "\n",
    "# comparando predição com o real\n",
    "print(classification_report(y_test, y_pred)) # precision, recall, f1-score, support"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
